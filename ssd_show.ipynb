{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-03T12:58:30.942286400Z",
     "start_time": "2024-11-03T12:58:30.772197800Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.utils.spectral_norm as spectral_norm\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import general_utils  # assuming general_utils.pickle_load is available\n",
    "from collections import defaultdict\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T12:58:31.277205200Z",
     "start_time": "2024-11-03T12:58:31.100197400Z"
    }
   },
   "id": "1416978d465b8bd3"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T12:58:31.942751400Z",
     "start_time": "2024-11-03T12:58:31.517960800Z"
    }
   },
   "id": "1af9d6a6d1f33c1c"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from ssd_network import  *\n",
    "from ssd_dataset import  *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T12:58:32.492203200Z",
     "start_time": "2024-11-03T12:58:32.043211300Z"
    }
   },
   "id": "efc698f47b56b98b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# prepare data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c641d736b947189"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\izaol\\\\fridge_food\\\\jedzenie\\\\train\\\\_annotations.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m csv_file \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mUsers\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mizaol\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mfridge_food\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mjedzenie\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m_annotations.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      2\u001B[0m images_dir \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mUsers\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mizaol\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mfridge_food\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mjedzenie\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 3\u001B[0m formatted_data, label_to_id \u001B[38;5;241m=\u001B[39m \u001B[43mprocess_annotations\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcsv_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimages_dir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mformatted_data.pkl\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m      6\u001B[0m     pickle\u001B[38;5;241m.\u001B[39mdump(formatted_data, f)\n",
      "File \u001B[1;32m~\\fridge_food\\ssd_dataset.py:25\u001B[0m, in \u001B[0;36mprocess_annotations\u001B[1;34m(csv_file, images_dir)\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# Struktura przechowująca dane dla każdego obrazu\u001B[39;00m\n\u001B[0;32m     23\u001B[0m image_annotations \u001B[38;5;241m=\u001B[39m defaultdict(\u001B[38;5;28;01mlambda\u001B[39;00m: {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mboxes\u001B[39m\u001B[38;5;124m\"\u001B[39m: [], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m\"\u001B[39m: []})\n\u001B[1;32m---> 25\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcsv_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m     26\u001B[0m     reader \u001B[38;5;241m=\u001B[39m csv\u001B[38;5;241m.\u001B[39mDictReader(f)\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m row \u001B[38;5;129;01min\u001B[39;00m reader:\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\izaol\\\\fridge_food\\\\jedzenie\\\\train\\\\_annotations.csv'"
     ]
    }
   ],
   "source": [
    "csv_file = r\"C:\\Users\\izaol\\fridge_food\\jedzenie\\train\\_annotations.csv\"\n",
    "images_dir = r\"C:\\Users\\izaol\\fridge_food\\jedzenie\\train\"\n",
    "formatted_data, label_to_id = process_annotations(csv_file, images_dir)\n",
    "\n",
    "with open('formatted_data.pkl', 'wb') as f:\n",
    "    pickle.dump(formatted_data, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T12:58:34.623979700Z",
     "start_time": "2024-11-03T12:58:33.678008400Z"
    }
   },
   "id": "556d00431dfeab73"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('formatted_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-02T19:35:29.112472200Z"
    }
   },
   "id": "433a1faffd5d11ed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-02T19:35:29.113471300Z"
    }
   },
   "id": "495e60715f8765fb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# config"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7825ba86473ae8b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "config['base_conv_conv_layers'] = [1, 16, 32, 64] \n",
    "config['base_conv_input_size'] = 32\n",
    "base_conv = BaseConv(config['base_conv_conv_layers'], \n",
    "                     config['base_conv_input_size'], chosen_fm=[-2, -1],\n",
    "                     norm=nn.BatchNorm2d, act_fn=nn.ReLU(), spectral=False)\n",
    "base_size = pretty_print_module_list(base_conv.module_list, torch.zeros([1,1,config['base_conv_input_size'], config['base_conv_input_size']]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-02T19:35:29.115474300Z"
    }
   },
   "id": "2ae5d8895f4ab452"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config['aux_conv_conv_layers'] = [64, 64, 64]\n",
    "config['aux_conv_input_size'] = 8\n",
    "aux_conv = AuxConv(config['aux_conv_conv_layers'], \n",
    "                   config['aux_conv_input_size'], norm=nn.BatchNorm2d, act_fn=nn.ReLU(), spectral=False)\n",
    "aux_size = pretty_print_module_list(aux_conv.module_list, torch.zeros(base_size[-1]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-02T19:35:29.116479200Z"
    }
   },
   "id": "7fc9a4d066f0083"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config['device'] = 'cpu'\n",
    "\n",
    "#model config\n",
    "config['n_classes'] = 50\n",
    "\n",
    "config['fm_channels'] = [base_size[i][1] for i in base_conv.fm_id] + [aux_size[i][1] for i in aux_conv.fm_id]\n",
    "config['fm_size'] = [base_size[i][-1] for i in base_conv.fm_id] + [aux_size[i][-1] for i in aux_conv.fm_id]\n",
    "config['n_fm'] = len(config['fm_channels'])\n",
    "config['fm_prior_aspect_ratio'] = [[1., 2., 3., 1/3, 0.5],\n",
    "                         [1., 2., 3., 0.5, 1/3],\n",
    "                         [1., 2., 3., 0.5, 1/3],\n",
    "                         [1., 2., 3., 0.5, 1/3],\n",
    "                         [1., 2., 0.5], \n",
    "                         [1., 2., 0.5]]\n",
    "\n",
    "config['fm_prior_aspect_ratio'] = config['fm_prior_aspect_ratio'][:config['n_fm']]\n",
    "\n",
    "config['fm_prior_scale'] = np.linspace(0.1, 0.9, config['n_fm']) #[0.2, 0.375, 0.55, 0.725, 0.9] # [0.1, 0.2, 0.375, 0.55, 0.725, 0.9] \n",
    "assert len(config['fm_prior_scale']) == len(config['fm_prior_aspect_ratio'])\n",
    "config['n_prior_per_pixel'] = [len(i)+1 for i in config['fm_prior_aspect_ratio']] #in fm1, each pixel has 4 priors\n",
    "\n",
    "# training config\n",
    "config['checkpoint'] = ''#output_folder/'checkpoint.pth'\n",
    "config['n_epoch'] = 40\n",
    "config['save_frequency'] = 20\n",
    "config['MultiStepLR_milestones'] = list(range(10, config['n_epoch'], 5))\n",
    "config['gamma'] = 0.5\n",
    "config['print_frequency'] = 1\n",
    "config['batch_size'] = 20\n",
    "config['iou_threshold'] = 0.5 #\n",
    "config['lr'] = 1e-3\n",
    "config['momentum'] = 0.9\n",
    "config['weight_decay'] = 5e-4\n",
    "config['pos_neg_ratio'] = 1.\n",
    "config['clip_grad'] = None\n",
    "config['multiboxloss_loc_cla_ratio'] = 0.25\n",
    "\n",
    "\n",
    "utils.img_size = base_size[0][-1]\n",
    "\n",
    "print(config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-02T19:35:29.119474Z"
    }
   },
   "id": "9ce35bbf0f2d3384"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#create model\n",
    "model = SSD(config, base_conv, aux_conv).to(config['device'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T19:35:29.122471800Z",
     "start_time": "2024-11-02T19:35:29.121481300Z"
    }
   },
   "id": "ff9c40c859c35e6b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bias = []\n",
    "not_bias = []\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        if 'bias' in name:\n",
    "            bias.append(param)\n",
    "        else:\n",
    "            not_bias.append(param)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    [{'params': bias, 'lr': config['lr'] * 2}, {'params': not_bias}],\n",
    "    lr=config['lr'],\n",
    "    weight_decay=config['weight_decay']\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer, \n",
    "    milestones=config['MultiStepLR_milestones'], \n",
    "    gamma=config['gamma']\n",
    ")\n",
    "print(model.priors_cxcy.shape)\n",
    "criterion = MultiBoxLoss(priors_cxcy=model.priors_cxcy, config=config)\n",
    "plot_loss = []\n",
    "\n",
    "# load checkpoint\n",
    "if config['checkpoint']:\n",
    "    print('Loaded checkpoint')\n",
    "    checkpoint = torch.load(config['checkpoint'], map_location=config['device'])\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    plot_loss = checkpoint['plot_loss']\n",
    "\n",
    "current_lr = scheduler.get_last_lr()\n",
    "print(\"Current learning rate:\", current_lr)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T19:35:29.122471800Z",
     "start_time": "2024-11-02T19:35:29.122471800Z"
    }
   },
   "id": "fd41fe3af90e533"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-01T12:51:07.939970200Z",
     "start_time": "2024-11-01T12:51:07.421801400Z"
    }
   },
   "id": "86ee4aa055a304eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "csv_file = r\"C:\\Users\\izaol\\fridge_food\\jedzenie\\train\\_annotations.csv\"\n",
    "images_dir = r\"C:\\Users\\izaol\\fridge_food\\jedzenie\\train\"\n",
    "formatted_data, label_to_id = process_annotations(csv_file, images_dir)\n",
    "\n",
    "with open('formatted_data.pkl', 'wb') as f:\n",
    "    pickle.dump(formatted_data, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-02T19:35:29.124472Z"
    }
   },
   "id": "c9c498c79c7e1e3c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "numb_class = len(label_to_id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-02T19:35:29.125472Z"
    }
   },
   "id": "924b0b5980615f16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainset = MyDataset('formatted_data.pkl', device=config['device'])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=config['batch_size'], collate_fn=trainset.collate_fn, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-02T19:35:29.128475300Z"
    }
   },
   "id": "79e8b238bf174ec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_progress_bar = tqdm(range(config['n_epoch']))\n",
    "epoch_progress_bar = tqdm(range(len(trainloader)))\n",
    "\n",
    "for e in range(config['n_epoch']):\n",
    "    training_progress_bar.update()\n",
    "    epoch_progress_bar.reset()\n",
    "\n",
    "    mean_loss = 0\n",
    "    for img, boxes, labels in trainloader:\n",
    "        epoch_progress_bar.update()\n",
    "        \n",
    "        img = img.unsqueeze(1)\n",
    "        \n",
    "        # img: tensor [n, c=1, h, w]\n",
    "        # boxes: list[n] of tensor[n_object, 4]\n",
    "        # labels: list[n] of tensor[n_object]\n",
    "        loc_output, cla_output, _ = model(img)\n",
    "        print(\"wymiar model: \", model.priors_cxcy.shape)\n",
    "        print(\"wymiary loc: \", loc_output.shape, \" wymiary cla: \", cla_output.shape, \" box: \", len(boxes), \" wymiary labels: \", len(labels))\n",
    "        loss = criterion(loc_output, cla_output, boxes, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        if config['clip_grad']:\n",
    "            utils.clip_gradient(optimizer, config['clip_grad'])\n",
    "        \n",
    "        optimizer.step()\n",
    "        mean_loss += loss.item()\n",
    "        # break\n",
    "    scheduler.step()\n",
    "    mean_loss /= len(trainloader)\n",
    "    plot_loss.append(mean_loss)\n",
    "    \n",
    "    if (e%config['print_frequency'] == config['print_frequency'] - 1) or (e==0):\n",
    "        print(mean_loss)\n",
    "        print(criterion.loc_loss.item(), criterion.cla_loss.item())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-02T19:35:29.130497800Z"
    }
   },
   "id": "5aa065762582ef23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-02T19:35:29.131481Z"
    }
   },
   "id": "e64440d1099641ff"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
